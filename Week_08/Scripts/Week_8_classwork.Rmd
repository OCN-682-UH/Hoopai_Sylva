---
title: "Week_8_classwork"
author: "Hanalei"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      error = FALSE)
```

```{r}
library(here)
library(tidyverse)
library(tidytext)
library(wordcloud2)
library(janeaustenr)
```

```{r}
#going over strings

words <- "this is my string... and no one... can take it awayyyyy"
words_vector <- c("apples","bananaz")

#paste words together
paste("high","low")

paste("high","low", sep = "~~~~")

#no space
paste0("...","///")

paste("if 'My Song' by Labi Siffre was made about strings, it'd go like...",words)

str_length(words_vector)

seq_data<-c("ASTEDFREFECF")
str_sub(seq_data, start=3, end = 5)

str_sub(seq_data, start = 3, end = 3) <- "808" # add an A in the 3rd position
seq_data

#deleting white space
badtreatments<-c("High", "  High", "High     ", "Low", "L o w")
badtreatments

str_trim(badtreatments)

#add space to make it to "5"
str_pad(badtreatments, 5, side = "right")

str_pad(badtreatments, 10, side = "right", pad = "1")

#uppercase / lowercase
x <- "I love R!"

str_to_upper(x)
str_to_lower(x)
str_to_title(x)


#pattern matching
data<-c("AAA", "TATA", "CTAG", "GCTT")
# find all the strings with an A
str_view(data, pattern = "A")

str_detect(data, pattern = "AT")

str_locate(data, pattern = "AT")

#regular expressions
vals<-c("a.b", "b.c","c.d")

str_replace(vals, "\\.", " ")

vals<-c("a.b.c", "b.c.d","c.d.e")
str_replace(vals, "\\.", "~")
# to take ALL out
str_replace_all(vals, "\\.", "~")


#Sequences
val2<-c("test 123", "test 456", "test")
str_subset(val2, "\\d") #<-"\\d" refers to only keeping text, no #'s


#Character class
str_count(val2, "[aeiou]")

str_count(val2, "[0-9]")


#Quantifiers
strings<-c("550-153-7578",
         "banana",
         "435.114.7586",
         "home: 672-442-6739")

phonenumbers <- "([2-9][0-9]{2})[- .]([0-9]{3})[- .]([0-9]{4})"

str_detect(strings, phonenumbers)

test<-str_subset(strings, phonenumbers)
test

test<-test%>%
  str_replace_all("\\.", "-")%>%
  str_replace_all(pattern = "[a-zA-Z]|\\:", replacement = "") %>%
  str_trim()
```

```{r}
#learning TIDYTEXT

head(austen_books())
tail(austen_books())

original_books <- austen_books() %>% # get all of Jane Austen's books
  group_by(book) %>%
  mutate(line = row_number(), # find every line
         chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",  # count the chapters (starts with the word chapter followed by a digit(d) or roman numerals(ivxlc)
                                                 ignore_case = TRUE))))%>% #ignore lower or uppercase
  ungroup()

tidy_books <- original_books %>%
  unnest_tokens(output = word, input = text) # add a column named word, with the input as the text column

head(get_stopwords())

cleaned_books <- tidy_books %>%
  anti_join(get_stopwords())

#counting words
cleaned_books %>% group_by(book)
  count(word, sort = TRUE)
  
  #sentiment analysis
  sent_word_counts <- tidy_books %>%
  inner_join(get_sentiments()) %>% # only keep pos or negative words
  count(word, sentiment, sort = TRUE) # count them
  
head(sent_word_counts)[1:3,]

sent_word_counts %>%
  filter(n > 150) %>% # take only if there are over 150 instances of it
  mutate(n = ifelse(sentiment == "negative", -n, n)) %>% # add a column where if the word is negative make the count negative
  mutate(word = reorder(word, n)) %>% # sort it so it gows from largest to smallest
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col() +
  coord_flip() +
  labs(y = "Contribution to sentiment")

sent_word_counts %>%
  filter(n > 150) %>% # take only if there are over 150 instances of it
  mutate(n = ifelse(sentiment == "negative", -n, n)) %>% # add a column where if the word is negative make the count negative
  mutate(word = reorder(word, n)) %>% # sort it so it gows from largest to smallest
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col() +
  coord_flip() +
  labs(y = "Contribution to sentiment")

words<-cleaned_books %>%
  count(word) %>% # count all the words
  arrange(desc(n))%>% # sort the words
  slice(1:100) #take the top 100

wordcloud2(words, shape = 'diamond', size=0.3)
```

